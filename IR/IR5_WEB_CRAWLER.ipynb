{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03bad942-f6a2-4063-ac3c-d6f4493fcafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling page 1...\n",
      "Crawling page 2...\n",
      "Crawling page 3...\n",
      "\n",
      "✅ Crawling completed successfully!\n",
      "\n",
      "                           Product Title    Price  \\\n",
      "0                   A Light in the Attic  Â£51.77   \n",
      "1                     Tipping the Velvet  Â£53.74   \n",
      "2                             Soumission  Â£50.10   \n",
      "3                          Sharp Objects  Â£47.82   \n",
      "4  Sapiens: A Brief History of Humankind  Â£54.23   \n",
      "\n",
      "                                        Product Link  \n",
      "0  https://books.toscrape.com/catalogue/a-light-i...  \n",
      "1  https://books.toscrape.com/catalogue/tipping-t...  \n",
      "2  https://books.toscrape.com/catalogue/soumissio...  \n",
      "3  https://books.toscrape.com/catalogue/sharp-obj...  \n",
      "4  https://books.toscrape.com/catalogue/sapiens-a...  \n",
      "\n",
      "Data saved to 'products.csv'\n"
     ]
    }
   ],
   "source": [
    "#%% Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "#%% Define the website URL pattern\n",
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "# Lists to store product data\n",
    "titles = []\n",
    "prices = []\n",
    "links = []\n",
    "\n",
    "#%% Crawl multiple pages\n",
    "for page in range(1, 4):  # first 3 pages\n",
    "    print(f\"Crawling page {page}...\")\n",
    "\n",
    "    # Replace {} with page number\n",
    "    url = base_url.format(page)\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # If page not found → stop\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ Page {page} not found. Stopping.\")\n",
    "        break\n",
    "\n",
    "    # Parse the HTML page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all product containers\n",
    "    products = soup.find_all('article', class_='product_pod')\n",
    "\n",
    "    # Extract details from each product\n",
    "    for product in products:\n",
    "        title = product.h3.a['title']  # product name\n",
    "        price = product.find('p', class_='price_color').text.strip()  # product price\n",
    "        link = \"https://books.toscrape.com/catalogue/\" + product.h3.a['href']  # full product link\n",
    "\n",
    "        # Add data to lists\n",
    "        titles.append(title)\n",
    "        prices.append(price)\n",
    "        links.append(link)\n",
    "\n",
    "#%% Create a DataFrame to store all data\n",
    "df = pd.DataFrame({\n",
    "    'Product Title': titles,\n",
    "    'Price': prices,\n",
    "    'Product Link': links\n",
    "})\n",
    "\n",
    "#%% Display few records\n",
    "print(\"\\n✅ Crawling completed successfully!\\n\")\n",
    "print(df.head())\n",
    "\n",
    "#%% Save data to CSV file\n",
    "df.to_csv(\"products.csv\", index=False)\n",
    "print(\"\\nData saved to 'products.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23824e6f-dff5-4c49-a132-099678373742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
